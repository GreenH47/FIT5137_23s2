{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning for the cashierdetail.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = r'rawdata\\cashierdetail.csv'\n",
    "# Load CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path, delimiter=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it means the cashierdetail.csv is formatted .\n",
    "## check data consistance inside the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noTrans,ArticleCode,Barcode,sizes,qty,basePrice,salePrice,DiscountType,discountPersen,discountRupiah,DiscExpenses,consignment,consignmentRp,subTotal,payment\n",
      "\n",
      "01SCS19E010001,BSC.AR-QG0007,00ARQG0093,ALL,1,80000,225000,2,0,125000,1,0,20000,100000,80000\n",
      "\n",
      "Row 50 has  14 of columns instead of 15\n",
      "01SCS19E010027,BSC.AR-SC0034,00ARSC0228,S,1,125000,315000,2,0,94500,1,0,44100,220500 176400\n",
      "\n",
      "Row 10855 has  14 of columns instead of 15\n",
      "01SCS19E300663,AR.ESB-SE003,20ARSE0247,M 1,204750,315000,2,0,63000,1,0,63000,252000,189000\n",
      "\n",
      "Writing 11558 line in correct file\n",
      "Writing 3 line in incorrect file\n"
     ]
    }
   ],
   "source": [
    "# check if every row has same number of columns\n",
    "with open(file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Get the number of columns in the header\n",
    "header_columns = len(lines[0].split(','))\n",
    "print(lines[0])\n",
    "print(lines[1])\n",
    "\n",
    "# Separate the lines into correct and incorrect lines\n",
    "correct_lines = []\n",
    "incorrect_lines = []\n",
    "incorrect_lines.append(lines[0])\n",
    "\n",
    "\n",
    "# Check each line\n",
    "for i, line in enumerate(lines):\n",
    "    num_columns = len(line.split(','))\n",
    "    if num_columns != header_columns:\n",
    "        print(f'Row {i} has  {num_columns} of columns instead of {header_columns}')\n",
    "        incorrect_lines.append(line)\n",
    "        print(line)\n",
    "    else:\n",
    "        correct_lines.append(line)\n",
    "\n",
    "# Write the correct lines to a new file\n",
    "correct_file_path = 'format_data/cashierdetail_final.csv'\n",
    "with open(correct_file_path, 'w') as f:\n",
    "    # print how many lines are written\n",
    "    print(f'Writing {len(correct_lines)} line in correct file')\n",
    "    f.writelines(correct_lines)\n",
    "\n",
    "# Write the incorrect lines to a new file\n",
    "incorrect_file_path = 'format_data/cashierdetail-incorrect-lines.csv'\n",
    "with open(incorrect_file_path, 'w') as f:\n",
    "    # print how many lines are written\n",
    "    print(f'Writing {len(incorrect_lines)} line in incorrect file')\n",
    "    f.writelines(incorrect_lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this case we can find that this two line missing a \",\" to isolate different value. we just need manually add one and merge with the correct version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 11559 line in final file\n"
     ]
    }
   ],
   "source": [
    "manual_file_path = r'format_data\\cashierdetail-incorrect-lines-manual.csv'\n",
    "\n",
    "# merage incorrect_file_path and correct_file_path\n",
    "df1 = pd.read_csv(correct_file_path, delimiter=',', encoding='utf-8')\n",
    "df2 = pd.read_csv(manual_file_path, delimiter=',', encoding='utf-8')\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df.to_csv('format_data/cashierdetail_final.csv', index=False)\n",
    "# print how many lines in the final file\n",
    "print(f'Writing {len(df)} line in final file')\n",
    "df = pd.read_csv('format_data/cashierdetail_final.csv', delimiter=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check depulicant/invalid value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "noTrans           0\n",
      "ArticleCode       0\n",
      "Barcode           0\n",
      "sizes             0\n",
      "qty               0\n",
      "basePrice         0\n",
      "salePrice         0\n",
      "DiscountType      0\n",
      "discountPersen    0\n",
      "discountRupiah    0\n",
      "DiscExpenses      0\n",
      "consignment       0\n",
      "consignmentRp     0\n",
      "subTotal          0\n",
      "payment           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "correct_file_path = 'format_data/cashierdetail_final.csv'\n",
    "df = pd.read_csv(correct_file_path, delimiter=',', encoding='utf-8')\n",
    "\n",
    "# except the colourName picture notes columns\n",
    "# df = df.drop(['Notes', 'referenceTrans'], axis=1)\n",
    "# check if there is null values in the DataFrame\n",
    "print(df.isnull().values.any())\n",
    "# print the number of null values in each column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data length: 11558\n",
      "drop duplicate data length: 11558\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "correct_file_path = 'format_data/cashierdetail_final.csv'\n",
    "df = pd.read_csv(correct_file_path, delimiter=',', encoding='utf-8')\n",
    "print(\"raw data length: \" + str(len(df)))\n",
    "\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "length = len(df)\n",
    "print(\"drop duplicate data length: \" + str(len(df)))\n",
    "\n",
    "#save to format_data folder\n",
    "df.to_csv('format_data/cashier_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qty:\n",
      " Min value: -1, Max value: 2\n",
      "basePrice:\n",
      " Min value: 90, Max value: 1150000\n",
      "salePrice:\n",
      " Min value: 15000, Max value: 1250000\n",
      "DiscountType:\n",
      " Min value: 0, Max value: 3\n",
      "discountPersen:\n",
      " Min value: 0, Max value: 0\n",
      "discountRupiah:\n",
      " Min value: 0, Max value: 324000\n",
      "DiscExpenses:\n",
      " Min value: 0, Max value: 1\n",
      "consignment:\n",
      " Min value: 0, Max value: 0\n",
      "consignmentRp:\n",
      " Min value: 5250, Max value: 187500\n",
      "subTotal:\n",
      " Min value: -111300, Max value: 1250000\n",
      "payment:\n",
      " Min value: -83475, Max value: 1062500\n",
      "11559\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def show_min_max(df):\n",
    "    # Iterate over each column in the DataFrame\n",
    "    for column in df.columns:\n",
    "        # Check if the column contains numerical values\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            # Find the minimum and maximum values in the column\n",
    "            min_val = df[column].min()\n",
    "            max_val = df[column].max()\n",
    "            # Print the column name with the corresponding min and max values\n",
    "            print(f'{column}:\\n Min value: {min_val}, Max value: {max_val}')\n",
    "\n",
    "df = pd.read_csv('format_data/cashierdetail_final.csv', delimiter=',', encoding='utf-8')\n",
    "# Call the function to show the min and max values for each column\n",
    "show_min_max(df)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check duplicate value in noTrans columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of duplicated transactions:  2380\n",
      "the number of duplicated transactions with same barcode:  noTrans    0\n",
      "Barcode    0\n",
      "count      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "correct_file_path = 'format_data/cashierdetail_final.csv'\n",
    "# Load CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(correct_file_path, delimiter=',', encoding='utf-8')\n",
    "\n",
    "count = df.groupby('noTrans').size()\n",
    "print('the number of duplicated transactions: ', count[count > 1].count())\n",
    "\n",
    "\n",
    "grouped = df.groupby(['noTrans', 'Barcode']).size().reset_index(name='count')\n",
    "filtered = grouped[grouped['count'] > 1]\n",
    "print('the number of duplicated transactions with same barcode: ', filtered.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================\n",
      "\n",
      "the negative quantity rows\n",
      "\n",
      "              noTrans   ArticleCode     Barcode sizes  qty  basePrice  \\\n",
      "11307  01SCS19E310345  AR.BPH-RB011  20ARRB0467     L   -1     103350   \n",
      "\n",
      "       salePrice  DiscountType  discountPersen  discountRupiah  DiscExpenses  \\\n",
      "11307     159000             2               0           47700             1   \n",
      "\n",
      "       consignment  consignmentRp  subTotal  payment  \n",
      "11307            0          27825   -111300   -83475  \n"
     ]
    }
   ],
   "source": [
    "# select the negative quantity rows\n",
    "df = pd.read_csv(correct_file_path, delimiter=',', encoding='utf-8')\n",
    "\n",
    "# negative quantity rows\n",
    "negative_qty_rows = df[df['qty'] < 0]\n",
    "print('\\n===================\\n')\n",
    "print('the negative quantity rows\\n')\n",
    "print(negative_qty_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because the 11307 row has the multiple negative value so it is invaild row. we need disposal this row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified DataFrame with negative quantity rows removed is saved \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "correct_file_path = 'format_data/cashierdetail_final.csv'\n",
    "df = pd.read_csv(correct_file_path, delimiter=',', encoding='utf-8')\n",
    "\n",
    "# Select rows with negative quantity values\n",
    "negative_qty_rows = df[df['qty'] < 0]\n",
    "\n",
    "# Delete rows with negative quantity values\n",
    "df = df.drop(negative_qty_rows.index)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv(correct_file_path, index=False)\n",
    "\n",
    "print(\"Modified DataFrame with negative quantity rows removed is saved \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the cashierdetail.csv has been cleaned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
